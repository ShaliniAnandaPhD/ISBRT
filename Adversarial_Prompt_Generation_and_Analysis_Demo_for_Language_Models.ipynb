{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMZFn/96S/LEVviX982y37e",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ShaliniAnandaPhD/ISBRT/blob/main/Adversarial_Prompt_Generation_and_Analysis_Demo_for_Language_Models.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Its primary function is to generate and analyze responses to adversarial prompts using a language model. Here's a breakdown of its key components and functionalities:\n",
        "\n",
        "1. **Importing Libraries**:\n",
        "   - `streamlit`: Used for creating web applications. It's the backbone of this script, providing the UI and server.\n",
        "   - `openai`: The library to interact with OpenAI's GPT models.\n",
        "   - `pandas`: Used for data manipulation and analysis.\n",
        "   - `altair`: A declarative statistical visualization library for Python.\n",
        "   - `langchain.llms.OpenAI`: Likely a custom wrapper around the OpenAI API.\n",
        "   - `textblob`: A library for processing textual data, used here for sentiment analysis.\n",
        "   - `nltk`: The Natural Language Toolkit, used for text processing and analysis.\n",
        "   - `textstat`: A library for calculating statistics from text to determine readability, complexity, and grade level.\n",
        "\n",
        "2. **Setup and Configuration**:\n",
        "   - Downloading necessary NLTK resources.\n",
        "   - Setting up Streamlit page configuration.\n",
        "   - Configuration of the OpenAI API with an API key.\n",
        "   - Handling possible exceptions during API setup.\n",
        "\n",
        "3. **Defining Personas**:\n",
        "   - A selection of different 'personas' (like Legal Expert, Ethical Philosopher, etc.) is defined. These personas likely represent different styles or focuses in responses.\n",
        "\n",
        "4. **Streamlit User Interface**:\n",
        "   - Creating a dropdown for selecting a persona.\n",
        "   - Input fields for users to enter a topic and additional context for the dilemma.\n",
        "   - A function to construct a custom prompt based on the selected persona and user inputs.\n",
        "\n",
        "5. **Generating and Analyzing Language Model Responses**:\n",
        "   - A function to get responses from the language model based on the custom prompt.\n",
        "   - Analyzing the response includes:\n",
        "     - Sentiment Analysis: Using `TextBlob` to find sentiment polarity of each sentence.\n",
        "     - Keyword Analysis: Using `nltk` to find the frequency of each word (excluding common words like \"also\" and stopwords).\n",
        "     - Readability Analysis: Using `textstat` to calculate various readability scores such as Flesch Reading Ease, SMOG Index, and Coleman-Liau Index.\n",
        "\n",
        "6. **Visualizations and Output**:\n",
        "   - Visualizing sentiment analysis and keyword frequency using Altair charts.\n",
        "   - A bar chart to represent the readability scores.\n",
        "\n",
        "7. **Streamlit App Execution**:\n",
        "   - The app provides an interactive web interface where the user can input their data, generate responses, and see the analysis and visualizations.\n",
        "\n",
        "8. **Key Functionalities**:\n",
        "   - The script allows users to simulate how different personas might respond to a given prompt, providing insights into various aspects of the generated text, including sentiment, keyword prominence, and readability.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "3KNZ6CTasW7I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install necessary libraries\n",
        "!pip install openai pandas matplotlib seaborn\n",
        "\n",
        "# Import libraries\n",
        "import openai\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Set up API access for LLMs (example for GPT-3)\n",
        "openai.api_key = 'key'\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ABPAytSd2UYP",
        "outputId": "154af238-f4eb-4da2-ae5c-6a915fd223cc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: openai in /usr/local/lib/python3.10/dist-packages (1.6.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (1.5.3)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (3.7.1)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.10/dist-packages (0.12.2)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from openai) (0.26.0)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (1.10.13)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.0)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.7 in /usr/local/lib/python3.10/dist-packages (from openai) (4.9.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2023.3.post1)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from pandas) (1.23.5)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (4.46.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (23.2)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (3.1.1)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.6)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2023.11.17)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.2)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas) (1.16.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_adversarial_prompt(topic):\n",
        "    # Enhanced logic for more complex scenarios\n",
        "    return f\"Discuss the ethical implications of {topic} in a futuristic setting.\"\n"
      ],
      "metadata": {
        "id": "X0rc0DXr3ThY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_llm_response(prompt):\n",
        "    # Enhanced response handling\n",
        "    response = openai.Completion.create(engine=\"davinci\", prompt=prompt, max_tokens=150)\n",
        "    return response.choices[0].text\n"
      ],
      "metadata": {
        "id": "JsXF6D2p3U9d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def analyze_response(response):\n",
        "    # Simulate advanced analysis for the demo\n",
        "    toxicity = np.random.uniform(0, 1)\n",
        "    bias = np.random.choice([\"gender\", \"race\", \"age\", \"none\"])\n",
        "    return {\"toxicity\": toxicity, \"bias\": bias}\n"
      ],
      "metadata": {
        "id": "0dmVEHdy3YA_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile adversarial_content_generation.py\n",
        "import streamlit as st\n",
        "import openai\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "\n",
        "st.set_page_config(page_title=\"Adversarial Content Generation\", page_icon=\"üîç\")\n",
        "\n",
        "def generate_adversarial_prompt(topic):\n",
        "    return f\"Discuss the ethical implications of {topic} in a futuristic setting.\"\n",
        "\n",
        "def get_llm_response(prompt):\n",
        "    response = openai.Completion.create(engine=\"davinci\", prompt=prompt, max_tokens=150)\n",
        "    return response.choices[0].text\n",
        "\n",
        "def analyze_response(response):\n",
        "    toxicity = np.random.uniform(0, 1)\n",
        "    bias = np.random.choice([\"gender\", \"race\", \"age\", \"none\"])\n",
        "    return {\"toxicity\": toxicity, \"bias\": bias}\n",
        "\n",
        "st.title('Adversarial Content Generation Demo')\n",
        "topic = st.text_input('Enter a topic:')\n",
        "if st.button('Generate and Analyze'):\n",
        "    prompt = generate_adversarial_prompt(topic)\n",
        "    st.write('Prompt:', prompt)\n",
        "    response = get_llm_response(prompt)\n",
        "    st.write('LLM Response:', response)\n",
        "\n",
        "    analysis = analyze_response(response)\n",
        "    st.write('Analysis:', analysis)\n",
        "\n",
        "    metrics = {\"toxicity\": [analysis['toxicity']], \"bias\": [0 if analysis['bias'] == \"none\" else 1]}\n",
        "    df = pd.DataFrame(metrics)\n",
        "    sns.lineplot(data=df)\n",
        "    st.pyplot(plt)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u6ZsOlm63z05",
        "outputId": "06e5423a-4a57-47b1-e224-101e8b105518"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing adversarial_content_generation.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile adversarial_sentence.py\n",
        "\n",
        "import streamlit as st\n",
        "import openai\n",
        "import pandas as pd\n",
        "import altair as alt\n",
        "from langchain.llms import OpenAI\n",
        "from textblob import TextBlob\n",
        "import nltk\n",
        "from nltk.tokenize import sent_tokenize, word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "import textstat\n",
        "\n",
        "# Ensure NLTK resources are downloaded\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "\n",
        "# Streamlit page configuration\n",
        "st.set_page_config(page_title=\"Enhanced Adversarial Dilemma Generator\", page_icon=\"üîç\")\n",
        "\n",
        "# Configuration and setup\n",
        "openai_api_key = 'api_key'  # Replace with your actual API key\n",
        "try:\n",
        "    llm = OpenAI(temperature=0.7, openai_api_key=openai_api_key)\n",
        "except Exception as e:\n",
        "    st.error(f\"Error setting up LLM: {e}\")\n",
        "    raise\n",
        "\n",
        "# Persona definitions\n",
        "personas = {\n",
        "    \"Legal Expert\": \"As a legal expert, \",\n",
        "    \"Ethical Philosopher\": \"From an ethical philosophy perspective, \",\n",
        "    \"Technology Enthusiast\": \"As a technology enthusiast, \"\n",
        "    # Add more personas as needed\n",
        "}\n",
        "\n",
        "# UI for persona selection\n",
        "selected_persona = st.selectbox(\"Select a Persona:\", list(personas.keys()))\n",
        "\n",
        "# UI for custom prompt creation\n",
        "topic = st.text_input(\"Enter the topic for the dilemma:\")\n",
        "additional_context = st.text_area(\"Provide any additional context or details:\")\n",
        "\n",
        "def get_custom_prompt():\n",
        "    prompt_base = f\"{personas[selected_persona]}Given the topic of '{topic}', {additional_context}\"\n",
        "    return prompt_base\n",
        "\n",
        "def get_llm_response(prompt):\n",
        "    # You might need to handle exceptions or errors here\n",
        "    return llm(prompt)\n",
        "\n",
        "# Enhanced Response Analysis\n",
        "def analyze_response(response):\n",
        "    # Sentiment Analysis\n",
        "    sentiment_scores = [TextBlob(sent).sentiment.polarity for sent in sent_tokenize(response)]\n",
        "    sentiment_df = pd.DataFrame({\"Sentence\": range(len(sentiment_scores)), \"Sentiment Score\": sentiment_scores})\n",
        "    sentiment_chart = alt.Chart(sentiment_df).mark_line().encode(x=\"Sentence\", y=\"Sentiment Score\")\n",
        "\n",
        "    # Frequency Distribution (Keyword Analysis)\n",
        "    words = word_tokenize(response)\n",
        "    words_lower = [word.lower() for word in words if word.isalpha() and word.lower() not in ['also']]\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "    filtered_words = [word for word in words_lower if word not in stop_words]\n",
        "    freq_dist = nltk.FreqDist(filtered_words)\n",
        "    freq_dist_df = pd.DataFrame(freq_dist.most_common(10), columns=[\"Word\", \"Frequency\"])\n",
        "    freq_chart = alt.Chart(freq_dist_df).mark_bar().encode(x='Word', y='Frequency')\n",
        "\n",
        "    # Readability Analysis\n",
        "    readability_scores = [\n",
        "        {\"Metric\": \"Flesch Reading Ease\", \"Score\": textstat.flesch_reading_ease(response)},\n",
        "        {\"Metric\": \"SMOG Index\", \"Score\": textstat.smog_index(response)},\n",
        "        {\"Metric\": \"Coleman-Liau Index\", \"Score\": textstat.coleman_liau_index(response)}\n",
        "    ]\n",
        "    readability_df = pd.DataFrame(readability_scores)\n",
        "    readability_chart = alt.Chart(readability_df).mark_bar().encode(\n",
        "        x=alt.X('Metric', sort=None),\n",
        "        y=alt.Y('Score'),\n",
        "        color='Metric'\n",
        "    )\n",
        "\n",
        "    return sentiment_chart, freq_chart, readability_chart\n",
        "\n",
        "# Streamlit UI elements\n",
        "st.title('Enhanced Adversarial Dilemma Generator')\n",
        "\n",
        "if st.button('Generate Response'):\n",
        "    custom_prompt = get_custom_prompt()\n",
        "    st.write('Custom Prompt:', custom_prompt)\n",
        "    response = get_llm_response(custom_prompt)\n",
        "    st.write('LLM Response:', response)\n",
        "\n",
        "    sentiment_chart, freq_chart, readability_chart = analyze_response(response)\n",
        "    st.subheader(\"Sentiment Analysis\")\n",
        "    st.altair_chart(sentiment_chart, use_container_width=True)\n",
        "    st.subheader(\"Keyword Analysis\")\n",
        "    st.altair_chart(freq_chart, use_container_width=True)\n",
        "    st.subheader(\"Readability Scores Visualization\")\n",
        "    st.altair_chart(readability_chart, use_container_width=True)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "47QFzpKxoimE"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}